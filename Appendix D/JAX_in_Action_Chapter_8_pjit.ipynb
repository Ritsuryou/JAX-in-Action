{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCirjpcFSPan"
      },
      "source": [
        "## ⚖️ Choose A or C:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5lNqNEGtLyO"
      },
      "source": [
        "## A: Emulating multi-device system on CPU\n",
        "\n",
        "Use this section to initialize a set of virtual devices on CPU if you have no access to a multi-device system.\n",
        "\n",
        "It can also help you prototype, debug and test your multi-device code locally before running it on the expensive system.\n",
        "\n",
        "Even in the case of using Google Colab it can help you prototype faster because a CPU runtime is faster to restart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypaH8OgftR_H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=8'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8ip1VKgterO"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tlh75iWutfVT",
        "outputId": "1fd2f900-4a3a-4ac7-f096-6f426343fc2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[CpuDevice(id=0),\n",
              " CpuDevice(id=1),\n",
              " CpuDevice(id=2),\n",
              " CpuDevice(id=3),\n",
              " CpuDevice(id=4),\n",
              " CpuDevice(id=5),\n",
              " CpuDevice(id=6),\n",
              " CpuDevice(id=7)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "jax.devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmk_qf6mKCZx"
      },
      "source": [
        "## (do not use) B: Setting up Colab TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMq70OC9wVHQ"
      },
      "source": [
        "#### [this section creates Colab TPU, which does not work with recent JAX versions anymore. Do not use TPU Runtime from Colab with this notebook]\n",
        "\n",
        "Use this section if you want to use Google Cloud TPU (and don't forget to change the Runtime type in \"Runtime\"-> \"Change runtime type\" -> \"TPU\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9_o0MwOu94x"
      },
      "outputs": [],
      "source": [
        "# in order to use TPU you have to run this cell before importing JAX\n",
        "import jax.tools.colab_tpu\n",
        "jax.tools.colab_tpu.setup_tpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aBy_QGmu-61",
        "outputId": "371f08da-64ff-4c18-a7d3-1db049cabae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tpu\n"
          ]
        }
      ],
      "source": [
        "from jax.lib import xla_bridge\n",
        "print(xla_bridge.get_backend().platform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c2IXWjRvFbj"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qLo4vNRvHc-",
        "outputId": "84ea03f5-1d4c-46c1-f73e-89e7b5f93da7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
              " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "jax.local_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C: Using Cloud TPU and a Local runtime in Colab"
      ],
      "metadata": {
        "id": "pXcZUT7WJv4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make preparations according to the following links:\n",
        "\n",
        "* Creating a Cloud TPU https://cloud.google.com/tpu/docs/managing-tpus-tpu-vm#tpu-vms\n",
        "\n",
        "* Preparing Jupyter and connect to a Local runtime https://research.google.com/colaboratory/local-runtimes.html\n"
      ],
      "metadata": {
        "id": "ps5o9t18KCb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'jax[tpu]' -f https://storage.googleapis.com/jax-releases/libtpu_releases.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DECNlXiNKuc2",
        "outputId": "a2f7ff00-8d5c-42df-c739-b146bef18542"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/libtpu_releases.html\r\n",
            "Requirement already satisfied: jax[tpu] in ./.local/lib/python3.8/site-packages (0.4.13)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in ./.local/lib/python3.8/site-packages (from jax[tpu]) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.21 in ./.local/lib/python3.8/site-packages (from jax[tpu]) (1.24.3)\n",
            "Requirement already satisfied: opt-einsum in ./.local/lib/python3.8/site-packages (from jax[tpu]) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.7 in ./.local/lib/python3.8/site-packages (from jax[tpu]) (1.10.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.6; python_version < \"3.10\" in ./.local/lib/python3.8/site-packages (from jax[tpu]) (6.8.0)\n",
            "Requirement already satisfied: jaxlib==0.4.13; extra == \"tpu\" in ./.local/lib/python3.8/site-packages (from jax[tpu]) (0.4.13)\n",
            "Requirement already satisfied: libtpu-nightly==0.1.dev20230622; extra == \"tpu\" in ./.local/lib/python3.8/site-packages (from jax[tpu]) (0.1.dev20230622)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.6; python_version < \"3.10\"->jax[tpu]) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp"
      ],
      "metadata": {
        "id": "9z7CUfFvJ7JN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jax.local_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RJ5XZCcKAYD",
        "outputId": "473d8adf-e348-4c4f-a25f-1bf75cc42c82"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
              " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRLNPE2Ese1D"
      },
      "source": [
        "## Using pjit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hICp5VhC6Bt",
        "outputId": "89179397-204e-4c94-f498-d6fc3706f9e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.4.13'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "jax.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e3HsZ2PIsl3t"
      },
      "outputs": [],
      "source": [
        "from jax.experimental.pjit import pjit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-Bocy386sr3n"
      },
      "outputs": [],
      "source": [
        "from jax import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1wKd0cB8iu5"
      },
      "source": [
        "### Old vmap+pmap example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2p2R6uG5tVpV"
      },
      "outputs": [],
      "source": [
        "def dot(v1, v2):\n",
        "  return jnp.vdot(v1, v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SDMWf5eIswdB"
      },
      "outputs": [],
      "source": [
        "rng_key = random.PRNGKey(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THq8XQoAs8CH",
        "outputId": "e4a7824f-20e8-4e81-8d18-8298e64ffae0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000000, 3), (10000000, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "vs = random.normal(rng_key, shape=(20_000_000,3))\n",
        "v1s = vs[:10_000_000,:]\n",
        "v2s = vs[10_000_000:,:]\n",
        "\n",
        "v1s.shape, v2s.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLM8V0BstMSD",
        "outputId": "9dbb6ea4-5d52-4085-bd12-1fcb0b7ec5b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8, 1250000, 3), (8, 1250000, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "v1sp = v1s.reshape((8, v1s.shape[0]//8, v1s.shape[1]))\n",
        "v2sp = v2s.reshape((8, v2s.shape[0]//8, v2s.shape[1]))\n",
        "\n",
        "v1sp.shape, v2sp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xf9UVhJcNHH4"
      },
      "outputs": [],
      "source": [
        "dot_parallel = jax.pmap(\n",
        "    jax.vmap(dot, in_axes=(0,0)),\n",
        "    in_axes=(0,0)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8rdtr2F_NI_g"
      },
      "outputs": [],
      "source": [
        "x_pmap = dot_parallel(v1sp,v2sp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF37XSrzNLE0",
        "outputId": "6a52937f-e373-4550-bb36-e1ddd8b15c0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1250000)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "x_pmap.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spEI1WDaNPXs",
        "outputId": "23fda118-4fa2-4b12-d40e-8e9081e92990"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000000,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "x_pmap = x_pmap.reshape((x_pmap.shape[0]*x_pmap.shape[1]))\n",
        "x_pmap.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUeiCdt_uUmv"
      },
      "source": [
        "### Replacing with pjit and 1D mesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "poE9ZsTevKdY"
      },
      "outputs": [],
      "source": [
        "from jax.sharding import Mesh\n",
        "from jax.sharding import PartitionSpec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SI0alZjP56SZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26EiJI9V5vUA",
        "outputId": "9e5a7882-8416-4e01-f44c-efa69e457512"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              "       TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              "       TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              "       TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
              "       TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              "       TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              "       TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              "       TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "devices = np.array(jax.devices())\n",
        "devices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9oP_tvkRIrI"
      },
      "source": [
        "Non-vectorized function won't work here because output partitioning works only for rank>=1 tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dR71WDupBiyb"
      },
      "outputs": [],
      "source": [
        "f = pjit(dot,\n",
        "         in_axis_resources=None,\n",
        "         out_axis_resources=PartitionSpec('devices')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "-fYCe7Q2BlSl",
        "outputId": "8203c557-ac55-4042-f28a-214e15fbd577"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/sharding_impls.py:248\u001b[0m, in \u001b[0;36mNamedSharding.is_compatible_aval\u001b[0;34m(self, aval_shape)\u001b[0m\n\u001b[1;32m    246\u001b[0m extra_msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m For scalars the PartitionSpec should be P()\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    247\u001b[0m              \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(aval_shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSharding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is only valid for values of rank at least \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parsed_pspec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but was applied to a value of rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(aval_shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextra_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: Sharding NamedSharding(mesh={'devices': 8}, spec=PartitionSpec('devices',)) is only valid for values of rank at least 1, but was applied to a value of rank 0. For scalars the PartitionSpec should be P()",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Mesh(devices, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevices\u001b[39m\u001b[38;5;124m'\u001b[39m,)):\n\u001b[0;32m----> 2\u001b[0m   x_pjit\u001b[38;5;241m=\u001b[39m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv1s\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv2s\u001b[49m\u001b[43m)\u001b[49m\n",
            "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/pjit.py:997\u001b[0m, in \u001b[0;36mpjit_check_aval_sharding\u001b[0;34m(shardings, flat_avals, names, what_aval, allow_uneven_sharding)\u001b[0m\n\u001b[1;32m    995\u001b[0m     s\u001b[38;5;241m.\u001b[39m_to_xla_hlo_sharding(\u001b[38;5;28mlen\u001b[39m(shape))\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 997\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    998\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOne of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhat_aval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is incompatible with its sharding \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    999\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;66;03m# Use the `OpSharding` proto to find out how many ways each dimension of\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;66;03m# the aval is sharded. This approach will work across all\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;66;03m# XLACompatibleSharding.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m hlo_sharding \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39m_to_xla_hlo_sharding(\u001b[38;5;28mlen\u001b[39m(shape))\n",
            "\u001b[0;31mValueError\u001b[0m: One of pjit outputs is incompatible with its sharding annotation NamedSharding(mesh={'devices': 8}, spec=PartitionSpec('devices',)): Sharding NamedSharding(mesh={'devices': 8}, spec=PartitionSpec('devices',)) is only valid for values of rank at least 1, but was applied to a value of rank 0. For scalars the PartitionSpec should be P()"
          ]
        }
      ],
      "source": [
        "with Mesh(devices, ('devices',)):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIfhsK4RRXCQ"
      },
      "source": [
        "Using a vectorized function that produces rank 1 tensor output. Input is replicated across all the devices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oy6ZX8j9_eVF"
      },
      "outputs": [],
      "source": [
        "f = pjit(jax.vmap(dot),\n",
        "         in_axis_resources=None,\n",
        "         out_axis_resources=PartitionSpec('devices')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fx46YXLx_4A_"
      },
      "outputs": [],
      "source": [
        "with Mesh(devices, ('devices',)):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nppWGEcvAK8w",
        "outputId": "7abc75ea-7e6a-4137-f66e-26f5e2b90199"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000000,)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "x_pjit.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0J-UmI0Balw",
        "outputId": "5eff76b4-9f69-4307-9a05-7fce7b3357fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(True, dtype=bool)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "jax.numpy.all(x_pjit == x_pmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAe6pb2wRhha"
      },
      "source": [
        "Input is sharded across all the devices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5_Y5ydczBxWl"
      },
      "outputs": [],
      "source": [
        "f = pjit(jax.vmap(dot),\n",
        "         in_axis_resources=PartitionSpec('devices'),\n",
        "         out_axis_resources=PartitionSpec('devices')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VZAAqX0eB-KV"
      },
      "outputs": [],
      "source": [
        "with Mesh(devices, ('devices',)):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8Ip8-pvCBKv",
        "outputId": "0af44bee-e400-4042-df3c-775eb05cf7dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000000,)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "x_pjit.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNxNE_yIRDYp",
        "outputId": "38942a94-0ffc-4fe0-8e8f-44e8c7541b69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(True, dtype=bool)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "jax.numpy.all(x_pjit == x_pmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpH7bHKvaVUV"
      },
      "source": [
        "The same as previous"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "j_8SmhxM2rcQ"
      },
      "outputs": [],
      "source": [
        "f = pjit(jax.vmap(dot),\n",
        "         in_axis_resources=(PartitionSpec('devices'), None),\n",
        "         out_axis_resources=PartitionSpec('devices')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "O7Cm1-hD2sjt"
      },
      "outputs": [],
      "source": [
        "with Mesh(devices, ('devices',)):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcMTZ_jZ2wzN",
        "outputId": "12a17058-b947-4291-f34a-ca8fb8407360"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000000,)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "x_pjit.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_jJCF2JaX8n"
      },
      "source": [
        "Also the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wXwWwPVQ5uJ6"
      },
      "outputs": [],
      "source": [
        "f = pjit(jax.vmap(dot),\n",
        "         in_axis_resources=PartitionSpec('devices', None),\n",
        "         out_axis_resources=PartitionSpec('devices')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_IA1QuIb5xgy"
      },
      "outputs": [],
      "source": [
        "with Mesh(devices, ('devices',)):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crGAiba_53Sw",
        "outputId": "f19d3195-da83-4ea9-b495-659de093dfb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000000,)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "x_pjit.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbUs_y6GaaAj"
      },
      "source": [
        "Trying more values in PartitionSpec than there are parameters in the function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1c6XEEa05KgF"
      },
      "outputs": [],
      "source": [
        "f = pjit(jax.vmap(dot),\n",
        "         in_axis_resources=(PartitionSpec('devices'), None, None),\n",
        "         out_axis_resources=PartitionSpec('devices')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "quKUJlda5LiU",
        "outputId": "05e98bfb-4053-4017-db3b-83ef46006e0f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Mesh(devices, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevices\u001b[39m\u001b[38;5;124m'\u001b[39m,)):\n\u001b[0;32m----> 2\u001b[0m   x_pjit\u001b[38;5;241m=\u001b[39m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv1s\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv2s\u001b[49m\u001b[43m)\u001b[49m\n",
            "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/pjit.py:871\u001b[0m, in \u001b[0;36mflatten_axis_resources\u001b[0;34m(what, tree, shardings, tupled_args)\u001b[0m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m       msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Given the corresponding argument being \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    868\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed, it looks like \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m might need to be wrapped in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    869\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma singleton tuple.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 871\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    873\u001b[0m axis_tree \u001b[38;5;241m=\u001b[39m shardings\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# Because we only have the `tree` treedef and not the full pytree here,\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# we construct a dummy tree to compare against. Revise this in callers?\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: pjit in_shardings specification must be a tree prefix of the positional arguments tuple passed to the `pjit`-decorated function. In particular, pjit in_shardings must either be a None, a PartitionSpec, or a tuple of length equal to the number of positional arguments. But pjit in_shardings is the wrong length: got a tuple or list of length 3 for an args tuple of length 2."
          ]
        }
      ],
      "source": [
        "with Mesh(devices, ('devices',)):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge3nElSNagye"
      },
      "source": [
        "Finally sharding both input parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Ep0i7qNpTIVI"
      },
      "outputs": [],
      "source": [
        "f = pjit(jax.vmap(dot),\n",
        "         in_axis_resources=(PartitionSpec('devices'), PartitionSpec('devices')),\n",
        "         out_axis_resources=PartitionSpec('devices')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "kbgIHp1ZTM9I"
      },
      "outputs": [],
      "source": [
        "with Mesh(devices, ('devices',)):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpTYrHoBTNWI",
        "outputId": "6d6eefc8-2121-4195-8c36-333f6bab63ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000000,)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "x_pjit.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UADUKdM2aM-N"
      },
      "source": [
        "### 2D mesh case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ARSVrRjtu0si"
      },
      "outputs": [],
      "source": [
        "from jax.sharding import PartitionSpec as P   # could be useful to reduce typing\n",
        "from jax.sharding import Mesh\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "HgfhAh2HbSHX"
      },
      "outputs": [],
      "source": [
        "rng_key = random.PRNGKey(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy0yLNP96WVF",
        "outputId": "988da26a-c9a3-488b-8293-1007c2c8c1a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4000, 10000), (4000, 10000))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "vs = random.normal(rng_key, shape=(8_000,10_000))\n",
        "v1s = vs[:4_000,:]\n",
        "v2s = vs[4_000:,:]\n",
        "\n",
        "v1s.shape, v2s.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePFmq1iObMoJ",
        "outputId": "4c913823-43fc-4cdd-a96d-d1650a82facf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              "        TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              "        TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              "        TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1)],\n",
              "       [TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              "        TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              "        TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              "        TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "devices = np.array(jax.devices()).reshape(2, 4)\n",
        "devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "UzfH0x9VbTLH"
      },
      "outputs": [],
      "source": [
        "def dot(v1, v2):\n",
        "  return jnp.vdot(v1, v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "xC7XX6Ebbv7e"
      },
      "outputs": [],
      "source": [
        "f = pjit(jax.vmap(dot),\n",
        "         in_axis_resources=(P('x', 'y'), P('x', 'y')),\n",
        "         out_axis_resources=P('x')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "bGS78ktTcgNh"
      },
      "outputs": [],
      "source": [
        "with Mesh(devices, ('x','y')):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh_riKu2cj_A",
        "outputId": "363d3d64-d49d-43e7-f1fc-aaf09abc7517"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000,)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "x_pjit.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je8_AQcdxYst"
      },
      "source": [
        "### Looking into HLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5rmPtoWxgtJ"
      },
      "source": [
        "You can't see any collective ops on the jaxpr level:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UfVcZ6Te67x",
        "outputId": "32bf1566-9b73-4d59-de9c-c6e565d2a930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[4000,10000]\u001b[39m b\u001b[35m:f32[4000,10000]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
            "    \u001b[39m\u001b[22m\u001b[22mc\u001b[35m:f32[4000]\u001b[39m = pjit[\n",
            "      in_shardings=(GSPMDSharding({devices=[2,4]0,1,2,3,4,5,6,7}), GSPMDSharding({devices=[2,4]0,1,2,3,4,5,6,7}))\n",
            "      jaxpr={ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; d\u001b[35m:f32[4000,10000]\u001b[39m e\u001b[35m:f32[4000,10000]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
            "          \u001b[39m\u001b[22m\u001b[22mf\u001b[35m:f32[4000]\u001b[39m = dot_general[dimension_numbers=(([1], [1]), ([0], [0]))] d\n",
            "            e\n",
            "        \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(f,) }\n",
            "      name=dot\n",
            "      out_shardings=(GSPMDSharding({devices=[2,4]0,1,2,3,4,5,6,7 last_tile_dim_replicate}),)\n",
            "      resource_env=ResourceEnv(Mesh(device_ids=array([[0, 1, 2, 3],\n",
            "       [4, 5, 6, 7]]), axis_names=('x', 'y')), ())\n",
            "    ] a b\n",
            "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }\n"
          ]
        }
      ],
      "source": [
        "with Mesh(devices, ('x','y')):\n",
        "  print(jax.make_jaxpr(f)(v1s,v2s))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU0c2nGbxlUi"
      },
      "source": [
        "But you can see them after the compilation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCgBvwYPr6yA",
        "outputId": "aeb9f3de-f383-42f9-d434-7826b578443d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HloModule pjit_dot, is_scheduled=true, entry_computation_layout={(f32[2000,2500]{1,0:T(8,128)}, f32[2000,2500]{1,0:T(8,128)})->f32[2000]{0:T(1024)}}\n",
            "\n",
            "%scalar_add_computation (scalar_lhs: f32[], scalar_rhs: f32[]) -> f32[] {\n",
            "  %scalar_rhs = f32[]{:T(256)} parameter(1)\n",
            "  %scalar_lhs = f32[]{:T(256)} parameter(0)\n",
            "  ROOT %add = f32[]{:T(256)} add(f32[]{:T(256)} %scalar_lhs, f32[]{:T(256)} %scalar_rhs)\n",
            "}\n",
            "\n",
            "%fused_computation (param_0.2: f32[2000,2500], param_1.2: f32[2000,2500]) -> f32[2000] {\n",
            "  %param_0.2 = f32[2000,2500]{1,0:T(8,128)} parameter(0)\n",
            "  %param_1.2 = f32[2000,2500]{1,0:T(8,128)} parameter(1)\n",
            "  %multiply.2 = f32[2000,2500]{1,0:T(8,128)} multiply(f32[2000,2500]{1,0:T(8,128)} %param_0.2, f32[2000,2500]{1,0:T(8,128)} %param_1.2)\n",
            "  %constant.2 = f32[]{:T(256)} constant(0)\n",
            "  ROOT %reduce.2 = f32[2000]{0:T(1024)} reduce(f32[2000,2500]{1,0:T(8,128)} %multiply.2, f32[]{:T(256)} %constant.2), dimensions={1}, to_apply=%scalar_add_computation, metadata={op_name=\"pjit(dot)/jit(main)/dot_general[dimension_numbers=(((1,), (1,)), ((0,), (0,))) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_9479/2294503736.py\" source_line=2}\n",
            "}\n",
            "\n",
            "ENTRY %main.6_spmd (param: f32[2000,2500], param.1: f32[2000,2500]) -> f32[2000] {\n",
            "  %param.1 = f32[2000,2500]{1,0:T(8,128)} parameter(1), sharding={devices=[2,4]0,1,2,3,4,5,6,7}\n",
            "  %param = f32[2000,2500]{1,0:T(8,128)} parameter(0), sharding={devices=[2,4]0,1,2,3,4,5,6,7}\n",
            "  %fusion = f32[2000]{0:T(1024)} fusion(f32[2000,2500]{1,0:T(8,128)} %param, f32[2000,2500]{1,0:T(8,128)} %param.1), kind=kLoop, calls=%fused_computation, metadata={op_name=\"pjit(dot)/jit(main)/dot_general[dimension_numbers=(((1,), (1,)), ((0,), (0,))) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_9479/2294503736.py\" source_line=2}, backend_config={\"flag_configs\":[],\"window_config\":{\"kernel_window_bounds\":[],\"output_window_bounds\":[\"32\",\"20\"],\"input_window_bounds\":[],\"estimated_cycles\":\"142736\",\"iteration_bounds\":[\"8\",\"1\"]},\"scoped_memory_configs\":[]}\n",
            "  ROOT %all-reduce = f32[2000]{0:T(1024)} all-reduce(f32[2000]{0:T(1024)} %fusion), channel_id=1, replica_groups={{0,1,2,3},{4,5,6,7}}, use_global_device_ids=true, to_apply=%scalar_add_computation, metadata={op_name=\"pjit(dot)/jit(main)/dot_general[dimension_numbers=(((1,), (1,)), ((0,), (0,))) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_9479/2294503736.py\" source_line=2}, backend_config={\"flag_configs\":[],\"barrier_config\":{\"barrier_type\":\"CUSTOM\",\"id\":\"0\"},\"scoped_memory_configs\":[{\"memory_space\":\"0\",\"offset\":\"0\",\"size\":\"67108864\"}],\"collective_algorithm_config\":{\"emitter\":\"SinglePhaseRingSumEmitter\"}}\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Thanks to https://github.com/google/jax/discussions/11275\n",
        "with Mesh(devices, ('x','y')):\n",
        "    modules = f.lower(v1s, v2s).compile().compiler_ir()\n",
        "    for hlo in modules:\n",
        "        print(hlo.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwkURlR91YHR"
      },
      "source": [
        "## MLP example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZySdFPR1fWr"
      },
      "source": [
        "### Preparing data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install these modules if you created a new empty cloud machine"
      ],
      "metadata": {
        "id": "wFW5RFD2NqOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvgUueADKium",
        "outputId": "58f96190-e080-4b57-d11c-31e2a72193b5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in ./.local/lib/python3.8/site-packages (2.13.1)\r\n",
            "Requirement already satisfied: absl-py>=1.0.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (2.0.0)\r\n",
            "Requirement already satisfied: astunparse>=1.6.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\r\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in ./.local/lib/python3.8/site-packages (from tensorflow) (23.5.26)\r\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./.local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\r\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in ./.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\r\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.59.2)\r\n",
            "Requirement already satisfied: h5py>=2.9.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (3.10.0)\r\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in ./.local/lib/python3.8/site-packages (from tensorflow) (2.13.1)\r\n",
            "Requirement already satisfied: libclang>=13.0.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (16.0.6)\r\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.24.3)\r\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in ./.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from tensorflow) (20.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./.local/lib/python3.8/site-packages (from tensorflow) (4.25.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (62.3.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in ./.local/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in ./.local/lib/python3.8/site-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\" in ./.local/lib/python3.8/site-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.23.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in ./.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in ./.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in ./.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (6.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1PpLK59K12_",
        "outputId": "9d3afa5a-c064-44bb-c680-2de97cceb6c5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_datasets in ./.local/lib/python3.8/site-packages (4.9.2)\n",
            "Requirement already satisfied: absl-py in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (2.0.0)\n",
            "Requirement already satisfied: array-record in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from tensorflow_datasets) (7.0)\n",
            "Requirement already satisfied: dm-tree in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (1.3.0)\n",
            "Requirement already satisfied: numpy in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied: promise in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (4.25.0)\n",
            "Requirement already satisfied: psutil in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (5.9.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (1.14.0)\n",
            "Requirement already satisfied: termcolor in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (2.3.0)\n",
            "Requirement already satisfied: toml in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (4.66.1)\n",
            "Requirement already satisfied: wrapt in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (1.15.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (6.1.0)\n",
            "Requirement already satisfied: typing_extensions; extra == \"epath\" in ./.local/lib/python3.8/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (4.5.0)\n",
            "Requirement already satisfied: zipp; extra == \"epath\" in /usr/lib/python3/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from promise->tensorflow_datasets) (1.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2019.11.28)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in ./.local/lib/python3.8/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.61.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "BrWQqOqTuz8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f87fafba-8075-49c3-d927-660a6004395a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-02 09:44:40.331239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/home/grigo/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import jax\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "data_dir = '/tmp/tfds'\n",
        "\n",
        "data, info = tfds.load(name=\"mnist\",\n",
        "                       data_dir=data_dir,\n",
        "                       as_supervised=True,\n",
        "                       with_info=True)\n",
        "\n",
        "data_train = data['train']\n",
        "data_test  = data['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "qEONTKl81iKa"
      },
      "outputs": [],
      "source": [
        "HEIGHT = 28\n",
        "WIDTH  = 28\n",
        "CHANNELS = 1\n",
        "NUM_PIXELS = HEIGHT * WIDTH * CHANNELS\n",
        "NUM_LABELS = info.features['label'].num_classes\n",
        "NUM_DEVICES = jax.device_count()\n",
        "BATCH_SIZE  = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "OwXDzEbT1j61"
      },
      "outputs": [],
      "source": [
        "def preprocess(img, label):\n",
        "  \"\"\"Resize and preprocess images.\"\"\"\n",
        "  return (tf.cast(img, tf.float32)/255.0), label\n",
        "\n",
        "train_data = tfds.as_numpy(\n",
        "    data_train.map(preprocess).batch(NUM_DEVICES*BATCH_SIZE).prefetch(1)\n",
        ")\n",
        "test_data  = tfds.as_numpy(\n",
        "    data_test.map(preprocess).batch(NUM_DEVICES*BATCH_SIZE).prefetch(1)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seqmmqqx1let",
        "outputId": "62518d23-4326-4ab3-d443-bb94daa87a58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "len(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkQT5al_1ove"
      },
      "source": [
        "### Preparing MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ajNo9yJY1mwQ"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap, value_and_grad\n",
        "from jax import random\n",
        "from jax.nn import swish, logsumexp, one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "oRrZN0Xh1qsl"
      },
      "outputs": [],
      "source": [
        "LAYER_SIZES = [28*28, 512, 10]\n",
        "PARAM_SCALE = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "SjxCJJLD1sEE"
      },
      "outputs": [],
      "source": [
        "def init_network_params(sizes, key=random.PRNGKey(0), scale=1e-2):\n",
        "  \"\"\"Initialize all layers for a fully-connected neural network with given sizes\"\"\"\n",
        "\n",
        "  def random_layer_params(m, n, key, scale=1e-2):\n",
        "    \"\"\"A helper function to randomly initialize weights and biases of a dense layer\"\"\"\n",
        "    w_key, b_key = random.split(key)\n",
        "    return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n",
        "\n",
        "  keys = random.split(key, len(sizes))\n",
        "  return [random_layer_params(m, n, k, scale) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n",
        "\n",
        "init_params = init_network_params(LAYER_SIZES, random.PRNGKey(0), scale=PARAM_SCALE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Kl6UEZ8d1t-s"
      },
      "outputs": [],
      "source": [
        "def predict(params, image):\n",
        "  \"\"\"Function for per-example predictions.\"\"\"\n",
        "  activations = image\n",
        "  for w, b in params[:-1]:\n",
        "    outputs = jnp.dot(w, activations) + b\n",
        "    activations = swish(outputs)\n",
        "\n",
        "  final_w, final_b = params[-1]\n",
        "  logits = jnp.dot(final_w, activations) + final_b\n",
        "  return logits\n",
        "\n",
        "batched_predict = vmap(predict, in_axes=(None, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Eo_z-kZ1yK6"
      },
      "source": [
        "### Loss and update functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "MNYNpeuPTyYj"
      },
      "outputs": [],
      "source": [
        "from jax.experimental.pjit import pjit\n",
        "from jax.sharding import PartitionSpec as P\n",
        "from jax.sharding import Mesh\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "rzxpgkMj1vwl"
      },
      "outputs": [],
      "source": [
        "INIT_LR = 1.0\n",
        "DECAY_RATE = 0.95\n",
        "DECAY_STEPS = 5\n",
        "NUM_EPOCHS  = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "tPkJ5dYp11Q4"
      },
      "outputs": [],
      "source": [
        "def loss(params, images, targets):\n",
        "  \"\"\"Categorical cross entropy loss function.\"\"\"\n",
        "  logits = batched_predict(params, images)\n",
        "  log_preds = logits - logsumexp(logits) # logsumexp trick https://gregorygundersen.com/blog/2020/02/09/log-sum-exp/\n",
        "  return -jnp.mean(targets*log_preds)\n",
        "\n",
        "def update(params, x, y, epoch_number):\n",
        "  loss_value, grads = value_and_grad(loss)(params, x, y)\n",
        "  lr = INIT_LR * DECAY_RATE ** (epoch_number / DECAY_STEPS)\n",
        "  return [(w - lr * dw, b - lr * db)\n",
        "          for (w, b), (dw, db) in zip(params, grads)], loss_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "e9LhptZvT8TJ"
      },
      "outputs": [],
      "source": [
        "f_update = pjit(update,\n",
        "         in_axis_resources=(None, P('x'), P('x'), None),\n",
        "         out_axis_resources=None\n",
        "         )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyXVUe62Epe"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B65sfV72T6bT",
        "outputId": "62efa105-22fc-45e8-ce5b-190dfb4aa44c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              "       TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              "       TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              "       TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
              "       TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              "       TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              "       TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              "       TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "devices = np.array(jax.devices())\n",
        "devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "MjDtmztL1925"
      },
      "outputs": [],
      "source": [
        "def batch_accuracy(params, images, targets):\n",
        "  images = jnp.reshape(images, (len(images), NUM_PIXELS))\n",
        "  predicted_class = jnp.argmax(batched_predict(params, images), axis=1)\n",
        "  return jnp.mean(predicted_class == targets)\n",
        "\n",
        "f_batch_accuracy = pjit(batch_accuracy,\n",
        "         in_axis_resources=(None, P('x'), P('x')),\n",
        "         out_axis_resources=None\n",
        "         )\n",
        "\n",
        "def accuracy(params, data):\n",
        "  accs = []\n",
        "  for images, targets in data:\n",
        "    accs.append(f_batch_accuracy(params, images, targets))\n",
        "  return jnp.mean(jnp.array(accs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGd4pczh2I1h",
        "outputId": "8a2a9b22-ea20-4cfb-8ba0-e5f60a0c21df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 in 1.88 sec\n",
            "Training set loss 0.6914460062980652\n",
            "Training set accuracy 0.8648548126220703\n",
            "Test set accuracy 0.874804675579071\n",
            "Epoch 1 in 1.02 sec\n",
            "Training set loss 0.6259850859642029\n",
            "Training set accuracy 0.8882258534431458\n",
            "Test set accuracy 0.893847644329071\n",
            "Epoch 2 in 0.99 sec\n",
            "Training set loss 0.6164931058883667\n",
            "Training set accuracy 0.8978224396705627\n",
            "Test set accuracy 0.901074230670929\n",
            "Epoch 3 in 0.97 sec\n",
            "Training set loss 0.6100647449493408\n",
            "Training set accuracy 0.906527042388916\n",
            "Test set accuracy 0.908984363079071\n",
            "Epoch 4 in 1.00 sec\n",
            "Training set loss 0.6044379472732544\n",
            "Training set accuracy 0.9142231941223145\n",
            "Test set accuracy 0.917285144329071\n",
            "Epoch 5 in 1.02 sec\n",
            "Training set loss 0.5995732545852661\n",
            "Training set accuracy 0.9211103320121765\n",
            "Test set accuracy 0.9248046875\n",
            "Epoch 6 in 0.96 sec\n",
            "Training set loss 0.5955986976623535\n",
            "Training set accuracy 0.9261746406555176\n",
            "Test set accuracy 0.929394543170929\n",
            "Epoch 7 in 0.98 sec\n",
            "Training set loss 0.5924407839775085\n",
            "Training set accuracy 0.9303634762763977\n",
            "Test set accuracy 0.931835949420929\n",
            "Epoch 8 in 0.98 sec\n",
            "Training set loss 0.5899019241333008\n",
            "Training set accuracy 0.9341034889221191\n",
            "Test set accuracy 0.936328113079071\n",
            "Epoch 9 in 0.95 sec\n",
            "Training set loss 0.5878012180328369\n",
            "Training set accuracy 0.9369791746139526\n",
            "Test set accuracy 0.938769519329071\n",
            "Epoch 10 in 0.97 sec\n",
            "Training set loss 0.5860352516174316\n",
            "Training set accuracy 0.9397329092025757\n",
            "Test set accuracy 0.942187488079071\n",
            "Epoch 11 in 1.01 sec\n",
            "Training set loss 0.5845362544059753\n",
            "Training set accuracy 0.9419769048690796\n",
            "Test set accuracy 0.944140613079071\n",
            "Epoch 12 in 1.04 sec\n",
            "Training set loss 0.5832522511482239\n",
            "Training set accuracy 0.9445866346359253\n",
            "Test set accuracy 0.945996105670929\n",
            "Epoch 13 in 0.94 sec\n",
            "Training set loss 0.5821421146392822\n",
            "Training set accuracy 0.9467973709106445\n",
            "Test set accuracy 0.947460949420929\n",
            "Epoch 14 in 0.89 sec\n",
            "Training set loss 0.5811706781387329\n",
            "Training set accuracy 0.9483432769775391\n",
            "Test set accuracy 0.948437511920929\n",
            "Epoch 15 in 0.93 sec\n",
            "Training set loss 0.5803174376487732\n",
            "Training set accuracy 0.9501218199729919\n",
            "Test set accuracy 0.9498047232627869\n",
            "Epoch 16 in 1.00 sec\n",
            "Training set loss 0.5795542597770691\n",
            "Training set accuracy 0.9512022733688354\n",
            "Test set accuracy 0.951171875\n",
            "Epoch 17 in 0.96 sec\n",
            "Training set loss 0.5788754820823669\n",
            "Training set accuracy 0.952698290348053\n",
            "Test set accuracy 0.952832043170929\n",
            "Epoch 18 in 0.97 sec\n",
            "Training set loss 0.5782554149627686\n",
            "Training set accuracy 0.9542940258979797\n",
            "Test set accuracy 0.9541992545127869\n",
            "Epoch 19 in 0.94 sec\n",
            "Training set loss 0.5776922106742859\n",
            "Training set accuracy 0.9555240869522095\n",
            "Test set accuracy 0.95556640625\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "params = init_params\n",
        "with Mesh(devices, ('x',)):\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    losses = []\n",
        "    for x, y in train_data:\n",
        "      x = jnp.reshape(x, (len(x), NUM_PIXELS))\n",
        "      y = one_hot(y, NUM_LABELS)\n",
        "      params, loss_value = f_update(params, x, y, epoch)\n",
        "      losses.append(jnp.sum(loss_value))\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    train_acc = accuracy(params, train_data)\n",
        "    test_acc = accuracy(params, test_data)\n",
        "    print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
        "    print(\"Training set loss {}\".format(jnp.mean(jnp.array(losses))))\n",
        "    print(\"Training set accuracy {}\".format(train_acc))\n",
        "    print(\"Test set accuracy {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some resources that might help you achieve weight sharding as well:\n",
        "https://github.com/google/jax/discussions/8649"
      ],
      "metadata": {
        "id": "CpzcEaL836k6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**!!! Do not forget to shutdown your Cloud TPU, or you'll spend much money on it!!!**"
      ],
      "metadata": {
        "id": "gJeoJJNGMrxA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0igAXyAE2dtf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}