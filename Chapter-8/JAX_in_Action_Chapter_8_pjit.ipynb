{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install the latest JAXlib version.\n",
        "# This code was originally tested on the 0.4.3 version, then updated to the 0.4.12\n",
        "!pip install --upgrade -q pip jax jaxlib"
      ],
      "metadata": {
        "id": "u5zBfJFH2Uyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCirjpcFSPan"
      },
      "source": [
        "## ⚖️ Choose A or C:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5lNqNEGtLyO"
      },
      "source": [
        "## A: Emulating multi-device system on CPU\n",
        "\n",
        "Use this section to initialize a set of virtual devices on CPU if you have no access to a multi-device system.\n",
        "\n",
        "It can also help you prototype, debug and test your multi-device code locally before running it on the expensive system.\n",
        "\n",
        "Even in the case of using Google Colab it can help you prototype faster because a CPU runtime is faster to restart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypaH8OgftR_H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=8'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8ip1VKgterO"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tlh75iWutfVT",
        "outputId": "1fd2f900-4a3a-4ac7-f096-6f426343fc2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[CpuDevice(id=0),\n",
              " CpuDevice(id=1),\n",
              " CpuDevice(id=2),\n",
              " CpuDevice(id=3),\n",
              " CpuDevice(id=4),\n",
              " CpuDevice(id=5),\n",
              " CpuDevice(id=6),\n",
              " CpuDevice(id=7)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "jax.devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmk_qf6mKCZx"
      },
      "source": [
        "## (do not use) B: Setting up Colab TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMq70OC9wVHQ"
      },
      "source": [
        "#### [this section creates Colab TPU, which at the moment does not work with pjit(), we need the Cloud TPU (section C) instead of Colab TPU]\n",
        "\n",
        "Use this section if you want to use Google Cloud TPU (and don't forget to change the Runtime type in \"Runtime\"-> \"Change runtime type\" -> \"TPU\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9_o0MwOu94x"
      },
      "outputs": [],
      "source": [
        "# in order to use TPU you have to run this cell before importing JAX\n",
        "import jax.tools.colab_tpu\n",
        "jax.tools.colab_tpu.setup_tpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aBy_QGmu-61",
        "outputId": "371f08da-64ff-4c18-a7d3-1db049cabae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tpu\n"
          ]
        }
      ],
      "source": [
        "from jax.lib import xla_bridge\n",
        "print(xla_bridge.get_backend().platform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c2IXWjRvFbj"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qLo4vNRvHc-",
        "outputId": "84ea03f5-1d4c-46c1-f73e-89e7b5f93da7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
              " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "jax.local_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C: Using Cloud TPU and a Local runtime in Colab"
      ],
      "metadata": {
        "id": "pXcZUT7WJv4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make preparations according to the following links:\n",
        "\n",
        "* Creating a Cloud TPU https://cloud.google.com/tpu/docs/managing-tpus-tpu-vm#tpu-vms\n",
        "\n",
        "* Preparing Jupyter and connect to a Local runtime https://research.google.com/colaboratory/local-runtimes.html\n"
      ],
      "metadata": {
        "id": "ps5o9t18KCb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'jax[tpu]>=0.2.16' -f https://storage.googleapis.com/jax-releases/libtpu_releases.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DECNlXiNKuc2",
        "outputId": "31e468e2-ce44-4ac7-92e2-ef7ee8816283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/libtpu_releases.html\r\n",
            "Requirement already satisfied: jax[tpu]>=0.2.16 in ./.local/lib/python3.8/site-packages (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.20 in ./.local/lib/python3.8/site-packages (from jax[tpu]>=0.2.16) (1.24.2)\n",
            "Requirement already satisfied: opt-einsum in ./.local/lib/python3.8/site-packages (from jax[tpu]>=0.2.16) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in ./.local/lib/python3.8/site-packages (from jax[tpu]>=0.2.16) (1.10.0)\n",
            "Requirement already satisfied: jaxlib==0.4.3; extra == \"tpu\" in ./.local/lib/python3.8/site-packages (from jax[tpu]>=0.2.16) (0.4.3)\n",
            "Requirement already satisfied: libtpu-nightly==0.1.dev20230207; extra == \"tpu\" in ./.local/lib/python3.8/site-packages (from jax[tpu]>=0.2.16) (0.1.dev20230207)\n",
            "Requirement already satisfied: requests; extra == \"tpu\" in /usr/local/lib/python3.8/dist-packages (from jax[tpu]>=0.2.16) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests; extra == \"tpu\"->jax[tpu]>=0.2.16) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests; extra == \"tpu\"->jax[tpu]>=0.2.16) (2019.11.28)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests; extra == \"tpu\"->jax[tpu]>=0.2.16) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests; extra == \"tpu\"->jax[tpu]>=0.2.16) (2.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp"
      ],
      "metadata": {
        "id": "9z7CUfFvJ7JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jax.local_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RJ5XZCcKAYD",
        "outputId": "dbff49d3-c1f8-4f82-c29b-b399609fff15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
              " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRLNPE2Ese1D"
      },
      "source": [
        "## Using pjit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hICp5VhC6Bt",
        "outputId": "6843198f-adea-4dd6-ecd9-320a8b659e9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.4.3'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "jax.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3HsZ2PIsl3t"
      },
      "outputs": [],
      "source": [
        "from jax.experimental.pjit import pjit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Bocy386sr3n"
      },
      "outputs": [],
      "source": [
        "from jax import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1wKd0cB8iu5"
      },
      "source": [
        "### Old vmap+pmap example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p2R6uG5tVpV"
      },
      "outputs": [],
      "source": [
        "def dot(v1, v2):\n",
        "  return jnp.vdot(v1, v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDMWf5eIswdB"
      },
      "outputs": [],
      "source": [
        "rng_key = random.PRNGKey(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THq8XQoAs8CH",
        "outputId": "7a5490ba-c1ff-4f66-df15-660f2f1f59cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000000, 3), (10000000, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "vs = random.normal(rng_key, shape=(20_000_000,3))\n",
        "v1s = vs[:10_000_000,:]\n",
        "v2s = vs[10_000_000:,:]\n",
        "\n",
        "v1s.shape, v2s.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLM8V0BstMSD",
        "outputId": "929e252f-4e46-4730-bbd5-23c3f003a383"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8, 1250000, 3), (8, 1250000, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "v1sp = v1s.reshape((8, v1s.shape[0]//8, v1s.shape[1]))\n",
        "v2sp = v2s.reshape((8, v2s.shape[0]//8, v2s.shape[1]))\n",
        "\n",
        "v1sp.shape, v2sp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf9UVhJcNHH4"
      },
      "outputs": [],
      "source": [
        "dot_parallel = jax.pmap(\n",
        "    jax.vmap(dot, in_axes=(0,0)),\n",
        "    in_axes=(0,0)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rdtr2F_NI_g"
      },
      "outputs": [],
      "source": [
        "x_pmap = dot_parallel(v1sp,v2sp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF37XSrzNLE0",
        "outputId": "8314faff-7149-42fe-b9fb-7b0799ac98e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1250000)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "x_pmap.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spEI1WDaNPXs",
        "outputId": "8aee775f-78ca-4a7d-d26e-d2ddf47e906f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000000,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "x_pmap = x_pmap.reshape((x_pmap.shape[0]*x_pmap.shape[1]))\n",
        "x_pmap.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUeiCdt_uUmv"
      },
      "source": [
        "### Replacing with pjit and 1D mesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poE9ZsTevKdY"
      },
      "outputs": [],
      "source": [
        "from jax.sharding import Mesh\n",
        "from jax.sharding import PartitionSpec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI0alZjP56SZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26EiJI9V5vUA",
        "outputId": "702d1f69-0c36-4b8a-adb0-f33086df95cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              "       TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              "       TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              "       TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
              "       TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              "       TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              "       TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              "       TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "devices = np.array(jax.devices())\n",
        "devices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9oP_tvkRIrI"
      },
      "source": [
        "Non-vectorized function won't work here because output partitioning works only for rank>=1 tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dR71WDupBiyb"
      },
      "outputs": [],
      "source": [
        "f = pjit(dot,\n",
        "         in_axis_resources=None,\n",
        "         out_axis_resources=PartitionSpec('devices')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-fYCe7Q2BlSl",
        "outputId": "31fd38df-a2ba-4d0c-b3e6-b6724488dbc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-02-11 20:27:04.753898: E external/org_tensorflow/tensorflow/compiler/xla/python/pjit.cc:476] cache miss fail: ValueError: One of pjit outputs is incompatible with its sharding annotation NamedSharding(mesh={'devices': 8}, spec=PartitionSpec('devices',)): Sharding NamedSharding(mesh={'devices': 8}, spec=PartitionSpec('devices',)) is only valid for values of rank at least 1, but was applied to a value of rank 0\n",
            "\n",
            "At:\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/jax/_src/pjit.py(866): pjit_check_aval_sharding\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/jax/_src/pjit.py(839): _pjit_jaxpr\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/jax/_src/linear_util.py(301): memoized_fun\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/jax/_src/pjit.py(411): common_infer_params\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/jax/_src/pjit.py(610): infer_params\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/jax/_src/pjit.py(115): _python_pjit_helper\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/jax/_src/pjit.py(155): cache_miss\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/jax/_src/traceback_util.py(200): reraise_with_filtered_traceback\n",
            "  /tmp/ipykernel_11279/2170211096.py(2): <module>\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3460): run_code\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3400): run_ast_nodes\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3221): run_cell_async\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3016): _run_cell\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2961): run_cell\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py(540): run_cell\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py(423): do_execute\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(729): execute_request\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(409): dispatch_shell\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(502): process_one\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(513): dispatch_queue\n",
            "  /usr/lib/python3.8/asyncio/events.py(81): _run\n",
            "  /usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n",
            "  /usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py(215): start\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py(728): start\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/traitlets/config/application.py(1043): launch_instance\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel_launcher.py(17): <module>\n",
            "  /usr/lib/python3.8/runpy.py(87): _run_code\n",
            "  /usr/lib/python3.8/runpy.py(194): _run_module_as_main\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/sharding.py:334\u001b[0m, in \u001b[0;36mNamedSharding.is_compatible_aval\u001b[0;34m(self, aval_shape)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(aval_shape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parsed_pspec):\n\u001b[0;32m--> 334\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    335\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSharding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is only valid for values of rank at least \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parsed_pspec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but was applied to a value of rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    337\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(aval_shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: Sharding NamedSharding(mesh={'devices': 8}, spec=PartitionSpec('devices',)) is only valid for values of rank at least 1, but was applied to a value of rank 0",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Mesh(devices, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevices\u001b[39m\u001b[38;5;124m'\u001b[39m,)):\n\u001b[0;32m----> 2\u001b[0m   x_pjit\u001b[38;5;241m=\u001b[39m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv1s\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv2s\u001b[49m\u001b[43m)\u001b[49m\n",
            "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/pjit.py:866\u001b[0m, in \u001b[0;36mpjit_check_aval_sharding\u001b[0;34m(shardings, flat_avals, what_aval, allow_uneven_sharding)\u001b[0m\n\u001b[1;32m    864\u001b[0m     s\u001b[38;5;241m.\u001b[39m_to_xla_op_sharding(\u001b[38;5;28mlen\u001b[39m(shape))\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 866\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOne of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhat_aval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is incompatible with its sharding \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    867\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Use the `OpSharding` proto to find out how many ways each dimension of\u001b[39;00m\n\u001b[1;32m    869\u001b[0m \u001b[38;5;66;03m# the aval is sharded. This approach will work across all\u001b[39;00m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# XLACompatibleSharding.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m op_sharding \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39m_to_xla_op_sharding(\u001b[38;5;28mlen\u001b[39m(shape))\n",
            "\u001b[0;31mValueError\u001b[0m: One of pjit outputs is incompatible with its sharding annotation NamedSharding(mesh={'devices': 8}, spec=PartitionSpec('devices',)): Sharding NamedSharding(mesh={'devices': 8}, spec=PartitionSpec('devices',)) is only valid for values of rank at least 1, but was applied to a value of rank 0"
          ]
        }
      ],
      "source": [
        "with Mesh(devices, ('devices',)):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIfhsK4RRXCQ"
      },
      "source": [
        "Using a vectorized function that produces rank 1 tensor output. Input is replicated across all the devices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy6ZX8j9_eVF"
      },
      "outputs": [],
      "source": [
        "f = pjit(jax.vmap(dot),\n",
        "         in_axis_resources=None,\n",
        "         out_axis_resources=PartitionSpec('devices')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fx46YXLx_4A_"
      },
      "outputs": [],
      "source": [
        "with Mesh(devices, ('devices',)):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nppWGEcvAK8w",
        "outputId": "909c4746-08f8-4856-d2d1-82ec9d1b798f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000000,)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "x_pjit.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0J-UmI0Balw",
        "outputId": "9000486b-e19c-4c0e-b221-24cbcd9d8b47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(True, dtype=bool)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "jax.numpy.all(x_pjit == x_pmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAe6pb2wRhha"
      },
      "source": [
        "Input is sharded across all the devices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_Y5ydczBxWl"
      },
      "outputs": [],
      "source": [
        "f = pjit(jax.vmap(dot),\n",
        "         in_axis_resources=PartitionSpec('devices'),\n",
        "         out_axis_resources=PartitionSpec('devices')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZAAqX0eB-KV"
      },
      "outputs": [],
      "source": [
        "with Mesh(devices, ('devices',)):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8Ip8-pvCBKv",
        "outputId": "31e9bc01-f367-43c7-fb2d-b3bf0c5b5603"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000000,)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "x_pjit.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNxNE_yIRDYp",
        "outputId": "c35ee277-d85f-4b9a-e556-7d28bad4b21d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(True, dtype=bool)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "jax.numpy.all(x_pjit == x_pmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpH7bHKvaVUV"
      },
      "source": [
        "The same as previous"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_8SmhxM2rcQ"
      },
      "outputs": [],
      "source": [
        "f = pjit(jax.vmap(dot),\n",
        "         in_axis_resources=(PartitionSpec('devices'), None),\n",
        "         out_axis_resources=PartitionSpec('devices')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7Cm1-hD2sjt"
      },
      "outputs": [],
      "source": [
        "with Mesh(devices, ('devices',)):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcMTZ_jZ2wzN",
        "outputId": "9cc8d1fa-a63b-41b1-9375-b7c2b07182d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000000,)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "x_pjit.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_jJCF2JaX8n"
      },
      "source": [
        "Also the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXwWwPVQ5uJ6"
      },
      "outputs": [],
      "source": [
        "f = pjit(jax.vmap(dot),\n",
        "         in_axis_resources=PartitionSpec('devices', None),\n",
        "         out_axis_resources=PartitionSpec('devices')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IA1QuIb5xgy"
      },
      "outputs": [],
      "source": [
        "with Mesh(devices, ('devices',)):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crGAiba_53Sw",
        "outputId": "b2dd077f-3932-4ac6-c44f-f80f4626b6de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000000,)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "x_pjit.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbUs_y6GaaAj"
      },
      "source": [
        "Trying more values in PartitionSpec than there are parameters in the function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1c6XEEa05KgF"
      },
      "outputs": [],
      "source": [
        "f = pjit(jax.vmap(dot),\n",
        "         in_axis_resources=(PartitionSpec('devices'), None, None),\n",
        "         out_axis_resources=PartitionSpec('devices')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "quKUJlda5LiU",
        "outputId": "93536eab-0bed-49f7-d3bf-f914765244ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-02-11 20:27:37.482894: E external/org_tensorflow/tensorflow/compiler/xla/python/pjit.cc:476] cache miss fail: ValueError: pjit in_axis_resources specification must be a tree prefix of the positional arguments tuple passed to the `pjit`-decorated function. In particular, pjit in_axis_resources must either be a None, a PartitionSpec, or a tuple of length equal to the number of positional arguments. But pjit in_axis_resources is the wrong length: got a tuple or list of length 3 for an args tuple of length 2.\n",
            "\n",
            "At:\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/jax/_src/pjit.py(706): flatten_axis_resources\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/jax/_src/pjit.py(739): _process_in_axis_resources\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/jax/_src/pjit.py(407): common_infer_params\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/jax/_src/pjit.py(610): infer_params\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/jax/_src/pjit.py(115): _python_pjit_helper\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/jax/_src/pjit.py(155): cache_miss\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/jax/_src/traceback_util.py(200): reraise_with_filtered_traceback\n",
            "  /tmp/ipykernel_11279/2170211096.py(2): <module>\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3460): run_code\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3400): run_ast_nodes\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3221): run_cell_async\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3016): _run_cell\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2961): run_cell\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py(540): run_cell\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py(423): do_execute\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(729): execute_request\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(409): dispatch_shell\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(502): process_one\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(513): dispatch_queue\n",
            "  /usr/lib/python3.8/asyncio/events.py(81): _run\n",
            "  /usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n",
            "  /usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py(215): start\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py(728): start\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/traitlets/config/application.py(1043): launch_instance\n",
            "  /home/grigo/.local/lib/python3.8/site-packages/ipykernel_launcher.py(17): <module>\n",
            "  /usr/lib/python3.8/runpy.py(87): _run_code\n",
            "  /usr/lib/python3.8/runpy.py(194): _run_module_as_main\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Mesh(devices, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevices\u001b[39m\u001b[38;5;124m'\u001b[39m,)):\n\u001b[0;32m----> 2\u001b[0m   x_pjit\u001b[38;5;241m=\u001b[39m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv1s\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv2s\u001b[49m\u001b[43m)\u001b[49m\n",
            "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/pjit.py:706\u001b[0m, in \u001b[0;36mflatten_axis_resources\u001b[0;34m(what, tree, shardings, tupled_args)\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m       msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Given the corresponding argument being \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    703\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed, it looks like \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m might need to be wrapped in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    704\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma singleton tuple.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 706\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_array:\n\u001b[1;32m    709\u001b[0m   axis_tree \u001b[38;5;241m=\u001b[39m shardings\n",
            "\u001b[0;31mValueError\u001b[0m: pjit in_axis_resources specification must be a tree prefix of the positional arguments tuple passed to the `pjit`-decorated function. In particular, pjit in_axis_resources must either be a None, a PartitionSpec, or a tuple of length equal to the number of positional arguments. But pjit in_axis_resources is the wrong length: got a tuple or list of length 3 for an args tuple of length 2."
          ]
        }
      ],
      "source": [
        "with Mesh(devices, ('devices',)):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge3nElSNagye"
      },
      "source": [
        "Finally sharding both input parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ep0i7qNpTIVI"
      },
      "outputs": [],
      "source": [
        "f = pjit(jax.vmap(dot),\n",
        "         in_axis_resources=(PartitionSpec('devices'), PartitionSpec('devices')),\n",
        "         out_axis_resources=PartitionSpec('devices')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbgIHp1ZTM9I"
      },
      "outputs": [],
      "source": [
        "with Mesh(devices, ('devices',)):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpTYrHoBTNWI",
        "outputId": "19c2c384-8a24-4ab8-a520-b3c9917583f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000000,)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "x_pjit.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UADUKdM2aM-N"
      },
      "source": [
        "### 2D mesh case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARSVrRjtu0si"
      },
      "outputs": [],
      "source": [
        "from jax.sharding import PartitionSpec as P   # could be useful to reduce typing\n",
        "from jax.sharding import Mesh\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgfhAh2HbSHX"
      },
      "outputs": [],
      "source": [
        "rng_key = random.PRNGKey(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy0yLNP96WVF",
        "outputId": "2867a172-9fc7-49a3-9d9f-342e1881684f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5000, 10000), (5000, 10000))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "vs = random.normal(rng_key, shape=(8_000,10_000))\n",
        "v1s = vs[:4_000,:]\n",
        "v2s = vs[4_000:,:]\n",
        "\n",
        "v1s.shape, v2s.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePFmq1iObMoJ",
        "outputId": "c8b2716d-62ff-4e11-ee09-f375345b925f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              "        TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              "        TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              "        TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1)],\n",
              "       [TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              "        TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              "        TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              "        TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "devices = np.array(jax.devices()).reshape(2, 4)\n",
        "devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzfH0x9VbTLH"
      },
      "outputs": [],
      "source": [
        "def dot(v1, v2):\n",
        "  return jnp.vdot(v1, v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC7XX6Ebbv7e"
      },
      "outputs": [],
      "source": [
        "f = pjit(jax.vmap(dot),\n",
        "         in_axis_resources=(P('x', 'y'), P('x', 'y')),\n",
        "         out_axis_resources=P('x')\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGS78ktTcgNh"
      },
      "outputs": [],
      "source": [
        "with Mesh(devices, ('x','y')):\n",
        "  x_pjit=f(v1s,v2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh_riKu2cj_A",
        "outputId": "5f7273c9-ee4f-4224-897b-8eb363a589b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000,)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "x_pjit.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je8_AQcdxYst"
      },
      "source": [
        "### Looking into HLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5rmPtoWxgtJ"
      },
      "source": [
        "You can't see any collective ops on the jaxpr level:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UfVcZ6Te67x",
        "outputId": "36a4cac8-dd96-4ad0-9f15-b6bff8126e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[5000,10000]\u001b[39m b\u001b[35m:f32[5000,10000]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
            "    \u001b[39m\u001b[22m\u001b[22mc\u001b[35m:f32[5000]\u001b[39m = pjit[\n",
            "      donated_invars=(False, False)\n",
            "      in_positional_semantics=(<_PositionalSemantics.GLOBAL: 1>, <_PositionalSemantics.GLOBAL: 1>)\n",
            "      in_shardings=(OpShardingSharding({devices=[2,4]0,1,2,3,4,5,6,7}), OpShardingSharding({devices=[2,4]0,1,2,3,4,5,6,7}))\n",
            "      inline=False\n",
            "      jaxpr={ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; d\u001b[35m:f32[5000,10000]\u001b[39m e\u001b[35m:f32[5000,10000]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
            "          \u001b[39m\u001b[22m\u001b[22mf\u001b[35m:f32[5000]\u001b[39m = dot_general[dimension_numbers=(([1], [1]), ([0], [0]))] d\n",
            "            e\n",
            "        \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(f,) }\n",
            "      keep_unused=False\n",
            "      name=dot\n",
            "      out_positional_semantics=_PositionalSemantics.GLOBAL\n",
            "      out_shardings=(OpShardingSharding({devices=[2,4]0,1,2,3,4,5,6,7 last_tile_dim_replicate}),)\n",
            "      resource_env=ResourceEnv(Mesh(device_ids=array([[0, 1, 2, 3],\n",
            "       [4, 5, 6, 7]]), axis_names=('x', 'y')), ())\n",
            "    ] a b\n",
            "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }\n"
          ]
        }
      ],
      "source": [
        "with Mesh(devices, ('x','y')):\n",
        "  print(jax.make_jaxpr(f)(v1s,v2s))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU0c2nGbxlUi"
      },
      "source": [
        "But you can see them after the compilation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCgBvwYPr6yA",
        "outputId": "adc4b12e-5ccb-4362-f87a-6b7e0010eaa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HloModule pjit_dot, is_scheduled=true, entry_computation_layout={(f32[2500,2500]{1,0:T(8,128)},f32[2500,2500]{1,0:T(8,128)})->f32[2500]{0:T(1024)}}\n",
            "\n",
            "%scalar_add_computation (scalar_lhs: f32[], scalar_rhs: f32[]) -> f32[] {\n",
            "  %scalar_rhs = f32[]{:T(256)} parameter(1)\n",
            "  %scalar_lhs = f32[]{:T(256)} parameter(0)\n",
            "  ROOT %add = f32[]{:T(256)} add(f32[]{:T(256)} %scalar_lhs, f32[]{:T(256)} %scalar_rhs)\n",
            "}\n",
            "\n",
            "%fused_computation (param_0.2: f32[2500,2500], param_1.2: f32[2500,2500]) -> f32[2500] {\n",
            "  %param_0.2 = f32[2500,2500]{1,0:T(8,128)} parameter(0)\n",
            "  %param_1.2 = f32[2500,2500]{1,0:T(8,128)} parameter(1)\n",
            "  %multiply.2 = f32[2500,2500]{1,0:T(8,128)} multiply(f32[2500,2500]{1,0:T(8,128)} %param_0.2, f32[2500,2500]{1,0:T(8,128)} %param_1.2)\n",
            "  %constant.2 = f32[]{:T(256)} constant(0)\n",
            "  ROOT %reduce.2 = f32[2500]{0:T(1024)} reduce(f32[2500,2500]{1,0:T(8,128)} %multiply.2, f32[]{:T(256)} %constant.2), dimensions={1}, to_apply=%scalar_add_computation, metadata={op_name=\"pjit(dot)/jit(main)/dot_general[dimension_numbers=(((1,), (1,)), ((0,), (0,))) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_11279/2294503736.py\" source_line=2}\n",
            "}\n",
            "\n",
            "ENTRY %main.6_spmd (param: f32[2500,2500], param.1: f32[2500,2500]) -> f32[2500] {\n",
            "  %param.1 = f32[2500,2500]{1,0:T(8,128)} parameter(1), sharding={devices=[2,4]0,1,2,3,4,5,6,7}\n",
            "  %param = f32[2500,2500]{1,0:T(8,128)} parameter(0), sharding={devices=[2,4]0,1,2,3,4,5,6,7}\n",
            "  %fusion = f32[2500]{0:T(1024)} fusion(f32[2500,2500]{1,0:T(8,128)} %param, f32[2500,2500]{1,0:T(8,128)} %param.1), kind=kLoop, calls=%fused_computation, metadata={op_name=\"pjit(dot)/jit(main)/dot_general[dimension_numbers=(((1,), (1,)), ((0,), (0,))) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_11279/2294503736.py\" source_line=2}, backend_config=\"{\\\"flag_configs\\\":[],\\\"window_config\\\":{\\\"kernel_window_bounds\\\":[],\\\"output_window_bounds\\\":[\\\"32\\\",\\\"20\\\"],\\\"input_window_bounds\\\":[],\\\"estimated_cycles\\\":\\\"177850\\\",\\\"iteration_bounds\\\":[\\\"10\\\",\\\"1\\\"]},\\\"scoped_memory_configs\\\":[]}\"\n",
            "  ROOT %all-reduce = f32[2500]{0:T(1024)} all-reduce(f32[2500]{0:T(1024)} %fusion), channel_id=1, replica_groups={{0,1,2,3},{4,5,6,7}}, use_global_device_ids=true, to_apply=%scalar_add_computation, metadata={op_name=\"pjit(dot)/jit(main)/dot_general[dimension_numbers=(((1,), (1,)), ((0,), (0,))) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_11279/2294503736.py\" source_line=2}, backend_config=\"{\\\"flag_configs\\\":[],\\\"barrier_config\\\":{\\\"barrier_type\\\":\\\"CUSTOM\\\",\\\"id\\\":\\\"0\\\"},\\\"scoped_memory_configs\\\":[{\\\"memory_space\\\":\\\"0\\\",\\\"offset\\\":\\\"0\\\",\\\"size\\\":\\\"67108864\\\"}],\\\"collective_algorithm_config\\\":{\\\"emitter\\\":\\\"RotatedPincerEmitter\\\",\\\"strategy\\\":\\\"StrategyRing\\\",\\\"debug\\\":\\\"\\\\nStrategyRing{colors:1 phases:1 cores:{4} nophase0:0 reserved_sflags:0 cross_module_on_2d_plane:0 has_reordering_map:0 use_routing_table_indices:1}\\\"}}\"\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Thanks to https://github.com/google/jax/discussions/11275\n",
        "with Mesh(devices, ('x','y')):\n",
        "    modules = f.lower(v1s, v2s).compile().compiler_ir()\n",
        "    for hlo in modules:\n",
        "        print(hlo.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwkURlR91YHR"
      },
      "source": [
        "## MLP example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZySdFPR1fWr"
      },
      "source": [
        "### Preparing data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install these modules if you created a new empty cloud machine"
      ],
      "metadata": {
        "id": "wFW5RFD2NqOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvgUueADKium",
        "outputId": "f27d8e6f-26ee-4c0d-a8e9-0298cdaa47ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.36ubuntu1 is an invalid version and will not be supported in a future release\r\n",
            "  warnings.warn(\r\n",
            "/usr/local/lib/python3.8/dist-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.23ubuntu1 is an invalid version and will not be supported in a future release\r\n",
            "  warnings.warn(\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |█████████████████▍              | 319.5 MB 144.1 MB/s eta 0:00:02"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |███████████████████████████████▎| 574.6 MB 276 kB/s eta 0:00:50"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 588.3 MB 8.9 kB/s \n",
            "\u001b[?25hCollecting absl-py>=1.0.0\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 102.5 MB/s \n",
            "\u001b[?25hCollecting astunparse>=1.6.0\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting google-pasta>=0.1.1\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 8.9 MB/s \n",
            "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
            "  Downloading grpcio-1.51.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.8 MB 91.7 MB/s \n",
            "\u001b[?25hCollecting h5py>=2.9.0\n",
            "  Downloading h5py-3.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 90.7 MB/s \n",
            "\u001b[?25hCollecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 96.7 MB/s \n",
            "\u001b[?25hCollecting libclang>=13.0.0\n",
            "  Downloading libclang-15.0.6.1-py2.py3-none-manylinux2010_x86_64.whl (21.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.5 MB 94.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.24.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in ./.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from tensorflow) (20.3)\n",
            "Collecting protobuf<3.20,>=3.9.2\n",
            "  Downloading protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 90.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (62.3.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 82.4 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 102.2 MB/s \n",
            "\u001b[?25hCollecting termcolor>=1.1.0\n",
            "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
            "Collecting typing-extensions>=3.6.6\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting wrapt>=1.11.0\n",
            "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 13.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\"\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.30.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 95.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 91.4 MB/s \n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.27.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 95.7 MB/s \n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[K     |████████████████████████████████| 781 kB 94.4 MB/s \n",
            "\u001b[?25hCollecting werkzeug>=1.0.1\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 101.2 MB/s \n",
            "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.1)\n",
            "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in ./.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (1.0.0)\n",
            "Installing collected packages: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, protobuf, cachetools, rsa, google-auth, requests-oauthlib, google-auth-oauthlib, markdown, tensorboard-data-server, tensorboard-plugin-wit, werkzeug, tensorboard, tensorflow-estimator, termcolor, typing-extensions, wrapt, tensorflow-io-gcs-filesystem, tensorflow\n",
            "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.1.21 gast-0.4.0 google-auth-2.16.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.1 h5py-3.8.0 keras-2.11.0 libclang-15.0.6.1 markdown-3.4.1 protobuf-3.19.6 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.30.0 termcolor-2.2.0 typing-extensions-4.4.0 werkzeug-2.2.2 wrapt-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1PpLK59K12_",
        "outputId": "2c58f2aa-c50a-46a1-dbf8-2fa664b53190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.36ubuntu1 is an invalid version and will not be supported in a future release\r\n",
            "  warnings.warn(\r\n",
            "/usr/local/lib/python3.8/dist-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.23ubuntu1 is an invalid version and will not be supported in a future release\r\n",
            "  warnings.warn(\n",
            "Collecting tensorflow_datasets\n",
            "  Downloading tensorflow_datasets-4.8.2-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from tensorflow_datasets) (7.0)\n",
            "Collecting dill\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 104.8 MB/s \n",
            "\u001b[?25hCollecting dm-tree\n",
            "  Downloading dm_tree-0.1.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
            "\u001b[K     |████████████████████████████████| 152 kB 110.1 MB/s \n",
            "\u001b[?25hCollecting etils[enp,epath]>=0.9.0\n",
            "  Downloading etils-1.0.0-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 107.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (1.24.2)\n",
            "Collecting promise\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (3.19.6)\n",
            "Requirement already satisfied: psutil in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (5.9.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (2.27.1)\n",
            "Collecting tensorflow-metadata\n",
            "  Downloading tensorflow_metadata-1.12.0-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (2.2.0)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 11.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt in ./.local/lib/python3.8/site-packages (from tensorflow_datasets) (1.14.1)\n",
            "Collecting importlib-resources; python_version < \"3.9\"\n",
            "  Downloading importlib_resources-5.10.2-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: typing_extensions; extra == \"epath\" in ./.local/lib/python3.8/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (4.4.0)\n",
            "Requirement already satisfied: zipp; extra == \"epath\" in /usr/lib/python3/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from promise->tensorflow_datasets) (1.14.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2019.11.28)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.8)\n",
            "Collecting googleapis-common-protos<2,>=1.52.0\n",
            "  Downloading googleapis_common_protos-1.58.0-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[K     |████████████████████████████████| 223 kB 103.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: promise\n",
            "  Building wheel for promise (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21485 sha256=73c0616d47fbaafbf82f3d1905e5301756920f772bc9c73de9dc34ab49496b93\n",
            "  Stored in directory: /home/grigo/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
            "Successfully built promise\n",
            "\u001b[31mERROR: importlib-resources 5.10.2 has requirement zipp>=3.1.0; python_version < \"3.10\", but you'll have zipp 1.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: dill, dm-tree, importlib-resources, etils, promise, googleapis-common-protos, tensorflow-metadata, toml, tqdm, tensorflow-datasets\n",
            "Successfully installed dill-0.3.6 dm-tree-0.1.8 etils-1.0.0 googleapis-common-protos-1.58.0 importlib-resources-5.10.2 promise-2.3 tensorflow-datasets-4.8.2 tensorflow-metadata-1.12.0 toml-0.10.2 tqdm-4.64.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrWQqOqTuz8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4746b5f-fe84-4fa3-e0c8-f75fa52c7940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/grigo/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /tmp/tfds/mnist/3.0.1...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 22.19 file/s]\n",
            "2023-02-11 20:30:05.457321: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
            "2023-02-11 20:30:05.457357: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDataset mnist downloaded and prepared to /tmp/tfds/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import jax\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "data_dir = '/tmp/tfds'\n",
        "\n",
        "data, info = tfds.load(name=\"mnist\",\n",
        "                       data_dir=data_dir,\n",
        "                       as_supervised=True,\n",
        "                       with_info=True)\n",
        "\n",
        "data_train = data['train']\n",
        "data_test  = data['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEONTKl81iKa"
      },
      "outputs": [],
      "source": [
        "HEIGHT = 28\n",
        "WIDTH  = 28\n",
        "CHANNELS = 1\n",
        "NUM_PIXELS = HEIGHT * WIDTH * CHANNELS\n",
        "NUM_LABELS = info.features['label'].num_classes\n",
        "NUM_DEVICES = jax.device_count()\n",
        "BATCH_SIZE  = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwXDzEbT1j61"
      },
      "outputs": [],
      "source": [
        "def preprocess(img, label):\n",
        "  \"\"\"Resize and preprocess images.\"\"\"\n",
        "  return (tf.cast(img, tf.float32)/255.0), label\n",
        "\n",
        "train_data = tfds.as_numpy(\n",
        "    data_train.map(preprocess).batch(NUM_DEVICES*BATCH_SIZE).prefetch(1)\n",
        ")\n",
        "test_data  = tfds.as_numpy(\n",
        "    data_test.map(preprocess).batch(NUM_DEVICES*BATCH_SIZE).prefetch(1)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seqmmqqx1let",
        "outputId": "98456f8c-0268-47b7-8608-c6f8e87e47b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "len(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkQT5al_1ove"
      },
      "source": [
        "### Preparing MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajNo9yJY1mwQ"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap, value_and_grad\n",
        "from jax import random\n",
        "from jax.nn import swish, logsumexp, one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRrZN0Xh1qsl"
      },
      "outputs": [],
      "source": [
        "LAYER_SIZES = [28*28, 512, 10]\n",
        "PARAM_SCALE = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjxCJJLD1sEE"
      },
      "outputs": [],
      "source": [
        "def init_network_params(sizes, key=random.PRNGKey(0), scale=1e-2):\n",
        "  \"\"\"Initialize all layers for a fully-connected neural network with given sizes\"\"\"\n",
        "\n",
        "  def random_layer_params(m, n, key, scale=1e-2):\n",
        "    \"\"\"A helper function to randomly initialize weights and biases of a dense layer\"\"\"\n",
        "    w_key, b_key = random.split(key)\n",
        "    return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n",
        "\n",
        "  keys = random.split(key, len(sizes))\n",
        "  return [random_layer_params(m, n, k, scale) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n",
        "\n",
        "init_params = init_network_params(LAYER_SIZES, random.PRNGKey(0), scale=PARAM_SCALE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl6UEZ8d1t-s"
      },
      "outputs": [],
      "source": [
        "def predict(params, image):\n",
        "  \"\"\"Function for per-example predictions.\"\"\"\n",
        "  activations = image\n",
        "  for w, b in params[:-1]:\n",
        "    outputs = jnp.dot(w, activations) + b\n",
        "    activations = swish(outputs)\n",
        "\n",
        "  final_w, final_b = params[-1]\n",
        "  logits = jnp.dot(final_w, activations) + final_b\n",
        "  return logits\n",
        "\n",
        "batched_predict = vmap(predict, in_axes=(None, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Eo_z-kZ1yK6"
      },
      "source": [
        "### Loss and update functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNYNpeuPTyYj"
      },
      "outputs": [],
      "source": [
        "from jax.experimental.pjit import pjit\n",
        "from jax.sharding import PartitionSpec as P\n",
        "from jax.sharding import Mesh\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzxpgkMj1vwl"
      },
      "outputs": [],
      "source": [
        "INIT_LR = 1.0\n",
        "DECAY_RATE = 0.95\n",
        "DECAY_STEPS = 5\n",
        "NUM_EPOCHS  = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPkJ5dYp11Q4"
      },
      "outputs": [],
      "source": [
        "def loss(params, images, targets):\n",
        "  \"\"\"Categorical cross entropy loss function.\"\"\"\n",
        "  logits = batched_predict(params, images)\n",
        "  log_preds = logits - logsumexp(logits) # logsumexp trick https://gregorygundersen.com/blog/2020/02/09/log-sum-exp/\n",
        "  return -jnp.mean(targets*log_preds)\n",
        "\n",
        "def update(params, x, y, epoch_number):\n",
        "  loss_value, grads = value_and_grad(loss)(params, x, y)\n",
        "  lr = INIT_LR * DECAY_RATE ** (epoch_number / DECAY_STEPS)\n",
        "  return [(w - lr * dw, b - lr * db)\n",
        "          for (w, b), (dw, db) in zip(params, grads)], loss_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9LhptZvT8TJ"
      },
      "outputs": [],
      "source": [
        "f_update = pjit(update,\n",
        "         in_axis_resources=(None, P('x'), P('x'), None),\n",
        "         out_axis_resources=None\n",
        "         )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyXVUe62Epe"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B65sfV72T6bT",
        "outputId": "86de9d36-18f7-41e3-9318-fdbb413fdcb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              "       TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              "       TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              "       TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
              "       TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              "       TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              "       TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              "       TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "devices = np.array(jax.devices())\n",
        "devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjDtmztL1925"
      },
      "outputs": [],
      "source": [
        "def batch_accuracy(params, images, targets):\n",
        "  images = jnp.reshape(images, (len(images), NUM_PIXELS))\n",
        "  predicted_class = jnp.argmax(batched_predict(params, images), axis=1)\n",
        "  return jnp.mean(predicted_class == targets)\n",
        "\n",
        "f_batch_accuracy = pjit(batch_accuracy,\n",
        "         in_axis_resources=(None, P('x'), P('x')),\n",
        "         out_axis_resources=None\n",
        "         )\n",
        "\n",
        "def accuracy(params, data):\n",
        "  accs = []\n",
        "  for images, targets in data:\n",
        "    accs.append(f_batch_accuracy(params, images, targets))\n",
        "  return jnp.mean(jnp.array(accs))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "! Be careful. This example does not work with Colab TPU because of Colab bug, it only works with Cloud TPU.\n",
        "\n",
        "https://github.com/google/jax/issues/8300\n",
        "\n",
        "If you want to use TPU, you need to build your own runtime on Google Cloud Platform (https://cloud.google.com/tpu/docs/jax-pods) and connects to it using Jupyter (https://research.google.com/colaboratory/local-runtimes.html)."
      ],
      "metadata": {
        "id": "ILZ4cJVzzAMU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGd4pczh2I1h",
        "outputId": "fd1be774-b86c-4d14-f5ef-5865f027fa36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 in 1.83 sec\n",
            "Training set loss 0.6914460062980652\n",
            "Training set accuracy 0.8648548126220703\n",
            "Test set accuracy 0.874804675579071\n",
            "Epoch 1 in 0.98 sec\n",
            "Training set loss 0.6259850859642029\n",
            "Training set accuracy 0.8882258534431458\n",
            "Test set accuracy 0.893847644329071\n",
            "Epoch 2 in 0.99 sec\n",
            "Training set loss 0.6164931058883667\n",
            "Training set accuracy 0.8978224396705627\n",
            "Test set accuracy 0.901074230670929\n",
            "Epoch 3 in 0.96 sec\n",
            "Training set loss 0.6100647449493408\n",
            "Training set accuracy 0.906527042388916\n",
            "Test set accuracy 0.908984363079071\n",
            "Epoch 4 in 1.05 sec\n",
            "Training set loss 0.6044379472732544\n",
            "Training set accuracy 0.9142231941223145\n",
            "Test set accuracy 0.917285144329071\n",
            "Epoch 5 in 1.06 sec\n",
            "Training set loss 0.5995732545852661\n",
            "Training set accuracy 0.9211103320121765\n",
            "Test set accuracy 0.9248046875\n",
            "Epoch 6 in 0.95 sec\n",
            "Training set loss 0.5955986976623535\n",
            "Training set accuracy 0.9261746406555176\n",
            "Test set accuracy 0.929394543170929\n",
            "Epoch 7 in 0.95 sec\n",
            "Training set loss 0.5924407839775085\n",
            "Training set accuracy 0.9303634762763977\n",
            "Test set accuracy 0.931835949420929\n",
            "Epoch 8 in 0.96 sec\n",
            "Training set loss 0.5899019241333008\n",
            "Training set accuracy 0.9341034889221191\n",
            "Test set accuracy 0.936328113079071\n",
            "Epoch 9 in 0.98 sec\n",
            "Training set loss 0.5878012180328369\n",
            "Training set accuracy 0.9369791746139526\n",
            "Test set accuracy 0.938769519329071\n",
            "Epoch 10 in 0.99 sec\n",
            "Training set loss 0.5860352516174316\n",
            "Training set accuracy 0.9397329092025757\n",
            "Test set accuracy 0.942187488079071\n",
            "Epoch 11 in 1.01 sec\n",
            "Training set loss 0.5845362544059753\n",
            "Training set accuracy 0.9419769048690796\n",
            "Test set accuracy 0.944140613079071\n",
            "Epoch 12 in 1.03 sec\n",
            "Training set loss 0.5832522511482239\n",
            "Training set accuracy 0.9445866346359253\n",
            "Test set accuracy 0.945996105670929\n",
            "Epoch 13 in 0.96 sec\n",
            "Training set loss 0.5821421146392822\n",
            "Training set accuracy 0.9467973709106445\n",
            "Test set accuracy 0.947460949420929\n",
            "Epoch 14 in 0.97 sec\n",
            "Training set loss 0.5811706781387329\n",
            "Training set accuracy 0.9483432769775391\n",
            "Test set accuracy 0.948437511920929\n",
            "Epoch 15 in 1.00 sec\n",
            "Training set loss 0.5803174376487732\n",
            "Training set accuracy 0.9501218199729919\n",
            "Test set accuracy 0.9498047232627869\n",
            "Epoch 16 in 0.99 sec\n",
            "Training set loss 0.5795542597770691\n",
            "Training set accuracy 0.9512022733688354\n",
            "Test set accuracy 0.951171875\n",
            "Epoch 17 in 0.94 sec\n",
            "Training set loss 0.5788754820823669\n",
            "Training set accuracy 0.952698290348053\n",
            "Test set accuracy 0.952832043170929\n",
            "Epoch 18 in 1.00 sec\n",
            "Training set loss 0.5782554149627686\n",
            "Training set accuracy 0.9542940258979797\n",
            "Test set accuracy 0.9541992545127869\n",
            "Epoch 19 in 1.01 sec\n",
            "Training set loss 0.5776922106742859\n",
            "Training set accuracy 0.9555240869522095\n",
            "Test set accuracy 0.95556640625\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "params = init_params\n",
        "with Mesh(devices, ('x',)):\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    losses = []\n",
        "    for x, y in train_data:\n",
        "      x = jnp.reshape(x, (len(x), NUM_PIXELS))\n",
        "      y = one_hot(y, NUM_LABELS)\n",
        "      params, loss_value = f_update(params, x, y, epoch)\n",
        "      losses.append(jnp.sum(loss_value))\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    train_acc = accuracy(params, train_data)\n",
        "    test_acc = accuracy(params, test_data)\n",
        "    print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
        "    print(\"Training set loss {}\".format(jnp.mean(jnp.array(losses))))\n",
        "    print(\"Training set accuracy {}\".format(train_acc))\n",
        "    print(\"Test set accuracy {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some resources that might help you achieve weight sharding as well:\n",
        "https://github.com/google/jax/discussions/8649"
      ],
      "metadata": {
        "id": "CpzcEaL836k6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**!!! Do not forget to shutdown your Cloud TPU, or you'll spend much money on it!!!**"
      ],
      "metadata": {
        "id": "gJeoJJNGMrxA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0igAXyAE2dtf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}